{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_Blocks_and_Layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAvYDZfteWPcHMw5MBq5bf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dmitri9149/TensorFlow-PyTorch-basics/blob/master/PyTorch_Blocks_and_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNXZO8ckVz9c"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz7s0w4o34iS"
      },
      "source": [
        "Some part of the code is based on d2l.ai book: http://d2l.ai/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4spfMK9X5a0"
      },
      "source": [
        "### basing on the d2l.ai book "
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8vqrvMFZK0F",
        "outputId": "08dcd868-b1e3-46ca-d753-7d6dc95d28e7"
      },
      "source": [
        "net = nn.Sequential(nn.Linear(20,256), nn.ReLU(), nn.Linear(256,10))\n",
        "\n",
        "X=torch.rand(2,20)\n",
        "net(X)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2511, -0.1936, -0.0241,  0.0806,  0.4070, -0.0377, -0.1729,  0.2600,\n",
              "          0.0812, -0.1201],\n",
              "        [-0.0955, -0.2428,  0.0699, -0.0722,  0.2934,  0.1410, -0.0233,  0.1487,\n",
              "         -0.0375,  0.0093]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWOcWWhTZtLj",
        "outputId": "0e38d96f-2346-4892-cd27-b7e7cc616298"
      },
      "source": [
        "net.forward(X)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2511, -0.1936, -0.0241,  0.0806,  0.4070, -0.0377, -0.1729,  0.2600,\n",
              "          0.0812, -0.1201],\n",
              "        [-0.0955, -0.2428,  0.0699, -0.0722,  0.2934,  0.1410, -0.0233,  0.1487,\n",
              "         -0.0375,  0.0093]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o-ZWGHzYMeC"
      },
      "source": [
        "class MLP(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)  # Hidden layer\n",
        "        self.out = nn.Linear(256, 10)  # Output layer\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.out(F.relu(self.hidden(X)))\n"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfl8Vjz4ZOCU",
        "outputId": "de6f0c20-5121-44c6-fefb-150eb87a3364"
      },
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0736, -0.0314, -0.2261, -0.1756,  0.2326, -0.0241, -0.0191, -0.2589,\n",
              "          0.0304,  0.2953],\n",
              "        [-0.0896, -0.0673, -0.0865, -0.2184,  0.1027, -0.0237,  0.1227, -0.1215,\n",
              "         -0.0883,  0.1061]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uZcmYXtat1q"
      },
      "source": [
        "### Custom Sequential Block"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYv1v61faxw5"
      },
      "source": [
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for block in args:\n",
        "            # Here, `block` is an instance of a `Module` subclass. We save it\n",
        "            # in the member variable `_modules` of the `Module` class, and its\n",
        "            # type is OrderedDict\n",
        "            self._modules[block] = block\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict guarantees that members will be traversed in the order\n",
        "        # they were added\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X\n",
        "\n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "594p1h-OjPWt",
        "outputId": "6f28cff8-bd13-4ddd-b76d-5b79b2bcf46c"
      },
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1326, -0.1398, -0.0072, -0.1961, -0.1421,  0.2422,  0.0093, -0.2049,\n",
              "         -0.1839, -0.2150],\n",
              "        [ 0.0554, -0.0163,  0.1596, -0.1814, -0.1092,  0.0948, -0.0435, -0.0639,\n",
              "         -0.1689, -0.1130]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbVgUwWC53nU"
      },
      "source": [
        "MyParallel model: several models use the same input, executed in paralle and the results of the models are concatenated in one output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA5lR60X6p0O"
      },
      "source": [
        "class MyParallel(nn.Module):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__()\n",
        "        for block in args:\n",
        "            # Here, `block` is an instance of a `Module` subclass. We save it\n",
        "            # in the member variable `_modules` of the `Module` class, and its\n",
        "            # type is OrderedDict\n",
        "            self._modules[block] = block\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict guarantees that members will be traversed in the order\n",
        "        # they were added\n",
        "        list_res=[]\n",
        "        for block in self._modules.values():\n",
        "          list_res.append(block(X))\n",
        "        concat_fin=torch.cat(list_res, dim = -1)\n",
        "        return concat_fin\n",
        "\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C91jHLAJMQ6"
      },
      "source": [
        "list_models = [nn.Linear(20,20),nn.Linear(20,20),nn.Linear(20,20)]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3fpmo-kI-xj",
        "outputId": "a879da02-bf6a-4546-bc1b-7160bcd77c40"
      },
      "source": [
        "net = MyParallel(nn.Linear(20,20),nn.Linear(20,20),nn.Linear(20,20))\n",
        "#X = torch.tensor([1,10])\n",
        "net(X)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.8378,  0.4368, -0.0836, -0.1544,  0.2442, -0.2566,  0.2811,  0.1476,\n",
              "         -0.0117, -0.5526, -0.5293,  0.4282, -0.3261,  0.0572,  0.1135, -0.0472,\n",
              "          0.4304,  0.0641,  0.1270, -0.2490, -0.5219,  0.1622, -0.3052, -0.1004,\n",
              "         -0.3826,  0.2613, -0.1517, -0.1587,  0.0329, -0.6025, -0.1988,  0.5530,\n",
              "         -0.0732, -0.1856, -0.4693,  0.2454,  0.4006,  0.2873, -0.0250,  0.0034,\n",
              "          0.5087, -0.5172,  0.1716, -0.0663,  0.0525, -0.4478,  0.1103,  0.6191,\n",
              "         -0.2156,  0.2591,  0.7326,  0.4514, -0.3594, -0.0020,  0.1164, -0.2802,\n",
              "          0.2221, -0.6473,  0.0984,  0.0911],\n",
              "        [-0.9652,  0.7165, -0.0055,  0.2759,  0.2285, -0.0468,  0.5170,  0.1011,\n",
              "          0.3189, -0.4060, -0.3416,  0.4551, -0.1653,  0.0941, -0.3136,  0.0370,\n",
              "         -0.3652, -0.3999,  0.1609,  0.1851, -0.8391,  0.4178,  0.3077, -0.1437,\n",
              "         -0.0901,  0.6757, -0.1040, -0.1135, -0.2441, -0.3089, -0.0906,  0.3661,\n",
              "          0.0928,  0.1847, -0.2205,  0.1841,  0.0726,  0.1751, -0.0042,  0.0546,\n",
              "          0.6348, -0.1654,  0.2303,  0.0805,  0.5775, -0.2790,  0.0471,  0.5444,\n",
              "          0.0652,  0.2680,  0.2310,  0.6197, -0.3979,  0.5611, -0.0739, -0.2611,\n",
              "         -0.1275, -0.4082, -0.1419,  0.5590]], grad_fn=<CatBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LP-xKOUCOPmN",
        "outputId": "dd518cdc-b788-4bb8-9642-ea05c9aaa30d"
      },
      "source": [
        "net = MyParallel(*list_models)\n",
        "net(X)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1488, -0.1264,  0.4381,  0.7137, -0.6443, -0.0645,  0.3388, -0.1104,\n",
              "          0.1917, -0.1900,  0.0039, -0.0677,  0.3395,  0.4270, -0.1230,  0.1560,\n",
              "         -0.8479,  0.0581, -0.2496, -0.0094,  0.8846,  0.1550, -0.0349,  0.2033,\n",
              "          0.0729, -0.1458,  0.0112, -0.8391, -0.4942,  0.6476,  0.1052,  0.2037,\n",
              "          0.2804,  0.0924,  0.3138, -0.0055,  0.3365,  0.0590,  0.2191,  0.1527,\n",
              "         -0.4742,  0.3799, -0.2444, -0.1667,  0.6810,  0.2701,  0.3883, -0.0997,\n",
              "          0.5334,  0.3969, -0.2636, -0.3816,  0.3145, -0.1896,  0.0775,  0.1546,\n",
              "          0.2503,  0.0388,  0.0965, -0.2552],\n",
              "        [-0.3358,  0.2262,  0.6327,  0.4836, -0.1902,  0.3506,  0.4452, -0.2592,\n",
              "         -0.2986, -0.1265, -0.3226,  0.0709,  0.3142, -0.1864,  0.1012, -0.0133,\n",
              "         -0.2613,  0.1467, -0.3816,  0.2484,  0.8834,  0.1443, -0.3368,  0.0731,\n",
              "          0.0561, -0.6898, -0.0343, -0.6978, -0.3101,  0.3910, -0.1583, -0.1757,\n",
              "         -0.0543,  0.0587,  0.0215,  0.1356,  0.3149, -0.0574,  0.0532,  0.2330,\n",
              "         -0.0717,  0.0149, -0.8836,  0.0370,  0.2832,  0.3605,  0.3813, -0.2545,\n",
              "          0.8146,  0.3136, -0.5619, -0.3078,  0.0009,  0.2014, -0.3067,  0.6007,\n",
              "          0.0549,  0.1374, -0.0128, -0.0181]], grad_fn=<CatBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnr94UYgR7bK"
      },
      "source": [
        "##### Nesting Modules\n",
        "class NestedBlocks(nn.Module):\n",
        "  def __init__(self,*args):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(nn.Linear(20,20),nn.Linear(20,20))\n",
        "    self.linear = nn.Linear(20,20)\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.linear(self.net(X))\n",
        "\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO6PLJdlTkkB",
        "outputId": "3fb23f50-ace4-45d3-8591-e3213ba44aa0"
      },
      "source": [
        "tensor = torch.ones([2,20])\n",
        "net = NestedBlocks()\n",
        "net(X)"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0190, -0.1838,  0.1627,  0.2060, -0.1366, -0.0127, -0.2582,  0.1960,\n",
              "         -0.2671, -0.0659,  0.0070,  0.0171, -0.0207, -0.2459, -0.2035,  0.0998,\n",
              "         -0.3006, -0.1006,  0.0776,  0.0604],\n",
              "        [ 0.2123, -0.0293,  0.0945,  0.1446, -0.0638, -0.0717, -0.0815, -0.0664,\n",
              "         -0.2449, -0.1005, -0.0660,  0.0515,  0.1943, -0.2329, -0.1916,  0.0756,\n",
              "         -0.1726, -0.2042, -0.2117,  0.0126]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    }
  ]
}